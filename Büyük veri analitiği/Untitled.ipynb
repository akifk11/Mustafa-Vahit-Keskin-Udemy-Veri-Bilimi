{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e743fbb3-acb6-4b0f-a44b-886fa31d2e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4267ebf9-5797-4291-9152-d46107f6747f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting findspark\n",
      "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: findspark\n",
      "Successfully installed findspark-2.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14420aae-fe33-4153-b9ff-12647d511ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"/Users/mehmetakifkiraz/spark/spark-3.3.1-bin-hadoop3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d497d41-b2a9-4e52-9d57-5ca6c170a396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61af8363-96e5-47a9-8d33-5208a055cd37",
   "metadata": {},
   "source": [
    "# Configrasyon ve Spark Bağlantısı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0fce5fa-c02d-4040-aa7b-45efa5a74a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yukarıda path ayarları yaptık \n",
    "# şimdi ise sesion ayarları yapacağız"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a94845d0-e0e2-4779-8452-b2fba9a1809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a5456db-ad0f-42ca-9e3a-1be41a52ed78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/03 09:56:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://mehmets-air.bbrouter:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=pyspark-shell>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc=SparkContext(master=\"local\")\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0207078e-9f76-4bed-b977-9a55c62827bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.1'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b5a9810-2763-4f8d-879c-32da7dcdfaf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mehmetakifkiraz'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.sparkUser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ac75a43-41d8-4a39-a2c8-a827ff371219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pyspark-shell'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.appName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "351eee85-0279-4ac3-885b-321b1693e5da",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PACKAGE_EXTENSIONS',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getnewargs__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_accumulatorServer',\n",
       " '_active_spark_context',\n",
       " '_assert_on_driver',\n",
       " '_batchSize',\n",
       " '_callsite',\n",
       " '_checkpointFile',\n",
       " '_conf',\n",
       " '_dictToJavaMap',\n",
       " '_do_init',\n",
       " '_encryption_enabled',\n",
       " '_ensure_initialized',\n",
       " '_gateway',\n",
       " '_getJavaStorageLevel',\n",
       " '_initialize_context',\n",
       " '_javaAccumulator',\n",
       " '_jsc',\n",
       " '_jvm',\n",
       " '_lock',\n",
       " '_next_accum_id',\n",
       " '_pickled_broadcast_vars',\n",
       " '_python_includes',\n",
       " '_repr_html_',\n",
       " '_serialize_to_jvm',\n",
       " '_temp_dir',\n",
       " '_unbatched_serializer',\n",
       " 'accumulator',\n",
       " 'addArchive',\n",
       " 'addFile',\n",
       " 'addPyFile',\n",
       " 'appName',\n",
       " 'applicationId',\n",
       " 'binaryFiles',\n",
       " 'binaryRecords',\n",
       " 'broadcast',\n",
       " 'cancelAllJobs',\n",
       " 'cancelJobGroup',\n",
       " 'defaultMinPartitions',\n",
       " 'defaultParallelism',\n",
       " 'dump_profiles',\n",
       " 'emptyRDD',\n",
       " 'environment',\n",
       " 'getCheckpointDir',\n",
       " 'getConf',\n",
       " 'getLocalProperty',\n",
       " 'getOrCreate',\n",
       " 'hadoopFile',\n",
       " 'hadoopRDD',\n",
       " 'master',\n",
       " 'newAPIHadoopFile',\n",
       " 'newAPIHadoopRDD',\n",
       " 'parallelize',\n",
       " 'pickleFile',\n",
       " 'profiler_collector',\n",
       " 'pythonExec',\n",
       " 'pythonVer',\n",
       " 'range',\n",
       " 'resources',\n",
       " 'runJob',\n",
       " 'sequenceFile',\n",
       " 'serializer',\n",
       " 'setCheckpointDir',\n",
       " 'setJobDescription',\n",
       " 'setJobGroup',\n",
       " 'setLocalProperty',\n",
       " 'setLogLevel',\n",
       " 'setSystemProperty',\n",
       " 'show_profiles',\n",
       " 'sparkHome',\n",
       " 'sparkUser',\n",
       " 'startTime',\n",
       " 'statusTracker',\n",
       " 'stop',\n",
       " 'textFile',\n",
       " 'uiWebUrl',\n",
       " 'union',\n",
       " 'version',\n",
       " 'wholeTextFiles']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1629d3ed-18b2-43d8-9213-7f38b81cabb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bu komut sesion'ı kapatmak için\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a8e0c53d-3d6b-4478-bfc6-8b19984b8040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://mehmets-air.bbrouter:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark_uygulama</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=pyspark_uygulama>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark import SparkContext\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"pyspark_uygulama\") \\\n",
    "    .config(\"spark.executer.memory\", \"16gb\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02392c0e-2774-4b8f-9912-b5177f1e8f9d",
   "metadata": {},
   "source": [
    "# Temel DataFrame İşlemleri\n",
    "### eskiden pandas dataframimiz vardı artık sparkdata framemimiz var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4185e895-9304-4e50-9335-7b11b23aedc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df=spark.read.csv(\"diabetes.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "be6d2f78-2723-4b99-b57a-0332810830fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Pregnancies: integer (nullable = true)\n",
      " |-- Glucose: integer (nullable = true)\n",
      " |-- BloodPressure: integer (nullable = true)\n",
      " |-- SkinThickness: integer (nullable = true)\n",
      " |-- Insulin: integer (nullable = true)\n",
      " |-- BMI: double (nullable = true)\n",
      " |-- DiabetesPedigreeFunction: double (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Outcome: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.printSchema()\n",
    "# şemaları ekrana bastırdık"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "da4cbccc-1272-4671-a7d2-924ffd3e7519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "41ee4c98-af68-4032-ae11-80c74f8423d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Pregnancies: int, Glucose: int, BloodPressure: int, SkinThickness: int, Insulin: int, BMI: double, DiabetesPedigreeFunction: double, Age: int, Outcome: int]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# şimdi ise veriyi cashleme işlemi yapacağız\n",
    "spark_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "39a208f8-1ced-42b6-8f01-d1611c346687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "408213f8-8a96-488a-ac7b-0b5ef59e5591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df=sns.load_dataset(\"diamonds\")\n",
    "df=df.select_dtypes(include=[\"int64\",\"float64\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3f17d6b2-12fe-4119-a15c-1b5dab0d9893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "efd2237c-a606-4b01-9bac-7bbdb4cb4e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#burada pythondaki temel fonksiyonları sparkta kullanamadığımızı gösteriyorum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5a6461c0-8c27-481c-afaf-4da8ba8358f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat  depth  table  price     x     y     z\n",
       "0   0.23   61.5   55.0    326  3.95  3.98  2.43\n",
       "1   0.21   59.8   61.0    326  3.89  3.84  2.31\n",
       "2   0.23   56.9   65.0    327  4.05  4.07  2.31\n",
       "3   0.29   62.4   58.0    334  4.20  4.23  2.63\n",
       "4   0.31   63.3   58.0    335  4.34  4.35  2.75"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f03ba6e9-6f76-4b89-9ffe-574294b4b009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Pregnancies=6, Glucose=148, BloodPressure=72, SkinThickness=35, Insulin=0, BMI=33.6, DiabetesPedigreeFunction=0.627, Age=50, Outcome=1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f913cbff-928c-4814-9345-b6642d363f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carat    float64\n",
       "depth    float64\n",
       "table    float64\n",
       "price      int64\n",
       "x        float64\n",
       "y        float64\n",
       "z        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ed5e7441-743f-410a-8a42-673ccbe1525a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pregnancies', 'int'),\n",
       " ('Glucose', 'int'),\n",
       " ('BloodPressure', 'int'),\n",
       " ('SkinThickness', 'int'),\n",
       " ('Insulin', 'int'),\n",
       " ('BMI', 'double'),\n",
       " ('DiabetesPedigreeFunction', 'double'),\n",
       " ('Age', 'int'),\n",
       " ('Outcome', 'int')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "041a4c4f-1df7-4f1d-8c8f-156a0d357f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3f1db897-80d4-4992-ac0c-24664d44f61d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'ndim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [60]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\n",
      "File \u001b[0;32m~/spark/spark-3.3.1-bin-hadoop3/python/pyspark/sql/dataframe.py:1988\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1978\u001b[0m \u001b[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[1;32m   1979\u001b[0m \n\u001b[1;32m   1980\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1985\u001b[0m \u001b[38;5;124;03m[Row(age=2), Row(age=5)]\u001b[39;00m\n\u001b[1;32m   1986\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m-> 1988\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1989\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name)\n\u001b[1;32m   1990\u001b[0m     )\n\u001b[1;32m   1991\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mapply(name)\n\u001b[1;32m   1992\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'ndim'"
     ]
    }
   ],
   "source": [
    "spark_df.ndim\n",
    "# gördüğünüz gibi aynı komut sparkta çalışmıyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3245257c-3322-4042-abe5-703c5e22b5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "|          6|    148|           72|           35|      0|33.6|                   0.627| 50|      1|\n",
      "|          1|     85|           66|           29|      0|26.6|                   0.351| 31|      0|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "78551f4f-7c64-4dab-a0c7-0b1e96d7295c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.count()\n",
    "# gözlem sayısını söylüyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7a046f64-6afe-4cc7-80ef-0e93ad832e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pregnancies',\n",
       " 'Glucose',\n",
       " 'BloodPressure',\n",
       " 'SkinThickness',\n",
       " 'Insulin',\n",
       " 'BMI',\n",
       " 'DiabetesPedigreeFunction',\n",
       " 'Age',\n",
       " 'Outcome']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "110d9bb0-0e42-4d92-8519-8ec62003406b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spark_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "002b9694-b08a-4ef9-85c0-152cedf8fad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------------+------------------+------------------+\n",
      "|summary|       Pregnancies|          Glucose|     BloodPressure|     SkinThickness|           Insulin|               BMI|DiabetesPedigreeFunction|               Age|           Outcome|\n",
      "+-------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------------+------------------+------------------+\n",
      "|  count|               768|              768|               768|               768|               768|               768|                     768|               768|               768|\n",
      "|   mean|3.8450520833333335|     120.89453125|       69.10546875|20.536458333333332| 79.79947916666667|31.992578124999977|      0.4718763020833327|33.240885416666664|0.3489583333333333|\n",
      "| stddev|  3.36957806269887|31.97261819513622|19.355807170644777|15.952217567727642|115.24400235133803| 7.884160320375441|       0.331328595012775|11.760231540678689| 0.476951377242799|\n",
      "|    min|                 0|                0|                 0|                 0|                 0|               0.0|                   0.078|                21|                 0|\n",
      "|    max|                17|              199|               122|                99|               846|              67.1|                    2.42|                81|                 1|\n",
      "+-------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f633047f-e56b-4d2d-ad32-3656886a87c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|          glucose|\n",
      "+-------+-----------------+\n",
      "|  count|              768|\n",
      "|   mean|     120.89453125|\n",
      "| stddev|31.97261819513622|\n",
      "|    min|                0|\n",
      "|    max|              199|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.describe(\"glucose\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "945a65cb-1978-473e-9c2a-2556e6313428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|glucose|pregnancies|\n",
      "+-------+-----------+\n",
      "|    148|          6|\n",
      "|     85|          1|\n",
      "|    183|          8|\n",
      "|     89|          1|\n",
      "|    137|          0|\n",
      "+-------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.select(\"glucose\",\"pregnancies\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b3d26c31-5af5-4368-98b8-313049be7315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.select(\"glucose\").distinct().count()\n",
    "# eşsiz değer sayısını gösteriyorum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "397c84fd-93f8-4a05-a909-efd19fc0503a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.select(\"glucose\").dropDuplicates().count()\n",
    "# bütün duplicate işlemleri silmiş olduk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ebcc3034-9495-4e9e-af17-74b5cbbfe216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "|Outcome_Pregnancies|  0|  1| 10| 11| 12| 13| 14| 15| 17|  2|  3|  4|  5|  6|  7|  8|  9|\n",
      "+-------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "|                  1| 38| 29| 10|  7|  4|  5|  2|  1|  1| 19| 27| 23| 21| 16| 25| 22| 18|\n",
      "|                  0| 73|106| 14|  4|  5|  5|  0|  0|  0| 84| 48| 45| 36| 34| 20| 16| 10|\n",
      "+-------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.crosstab(\"Outcome\",\"Pregnancies\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d2a58a27-1ac9-4c88-af7b-6026fba371fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.dropna().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a04b46c9-33a5-4209-8768-585efe3cfc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "|          6|    148|           72|           35|      0|33.6|                   0.627| 50|      1|\n",
      "|          1|     85|           66|           29|      0|26.6|                   0.351| 31|      0|\n",
      "|          8|    183|           64|            0|      0|23.3|                   0.672| 32|      1|\n",
      "|          1|     89|           66|           23|     94|28.1|                   0.167| 21|      0|\n",
      "|          0|    137|           40|           35|    168|43.1|                   2.288| 33|      1|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.dropna().show(5)\n",
    "#eksik gözlemlerden kurtulup yazma işlemi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306e9d08-a195-48b3-9fc4-8c74bac0e364",
   "metadata": {},
   "source": [
    "# Gözlem seçme işlemleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "172f01ff-6962-4f78-893f-602cca7a5a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bu işlemler için filter fonksiyonu kullanılır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3b4559ac-41ee-4b06-b694-8c02893e3e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.filter(spark_df.Age >40).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f7064882-2b2a-47f5-a38c-a43bacb49e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|Outcome|count|\n",
      "+-------+-----+\n",
      "|      1|  268|\n",
      "|      0|  500|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.groupby(\"Outcome\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bcfa5d46-5fdc-4a54-a9c3-e5f3b181516e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|Outcome|         avg(BMI)|\n",
      "+-------+-----------------+\n",
      "|      1|35.14253731343278|\n",
      "|      0|30.30419999999996|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.groupby(\"Outcome\").agg({\"BMI\":\"mean\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6ebb5d40-a8f3-436e-a9e6-6c69b171210e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+\n",
      "| BMI|yeni_degisken|\n",
      "+----+-------------+\n",
      "|33.6|         16.8|\n",
      "|26.6|         13.3|\n",
      "|23.3|        11.65|\n",
      "|28.1|        14.05|\n",
      "|43.1|        21.55|\n",
      "|25.6|         12.8|\n",
      "|31.0|         15.5|\n",
      "|35.3|        17.65|\n",
      "|30.5|        15.25|\n",
      "| 0.0|          0.0|\n",
      "|37.6|         18.8|\n",
      "|38.0|         19.0|\n",
      "|27.1|        13.55|\n",
      "|30.1|        15.05|\n",
      "|25.8|         12.9|\n",
      "|30.0|         15.0|\n",
      "|45.8|         22.9|\n",
      "|29.6|         14.8|\n",
      "|43.3|        21.65|\n",
      "|34.6|         17.3|\n",
      "+----+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.withColumn(\"yeni_degisken\",spark_df.BMI/2).select(\"BMI\",\"yeni_degisken\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "16e96762-37de-4a4b-b1ae-d75fa39a59b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pregnancies',\n",
       " 'Glucose',\n",
       " 'BloodPressure',\n",
       " 'SkinThickness',\n",
       " 'Insulin',\n",
       " 'BMI',\n",
       " 'DiabetesPedigreeFunction',\n",
       " 'Age',\n",
       " 'bagimli_degisken']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#şimdi ise isim değiştirme yapıyoruz\n",
    "spark_df.withColumnRenamed(\"Outcome\",\"bagimli_degisken\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ccdc6c54-ba17-4c99-8477-651c297263c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "|          6|    148|           72|           35|      0|33.6|                   0.627| 50|      1|\n",
      "|          1|     85|           66|           29|      0|26.6|                   0.351| 31|      0|\n",
      "|          8|    183|           64|            0|      0|23.3|                   0.672| 32|      1|\n",
      "|          1|     89|           66|           23|     94|28.1|                   0.167| 21|      0|\n",
      "|          0|    137|           40|           35|    168|43.1|                   2.288| 33|      1|\n",
      "|          5|    116|           74|            0|      0|25.6|                   0.201| 30|      0|\n",
      "|          3|     78|           50|           32|     88|31.0|                   0.248| 26|      1|\n",
      "|         10|    115|            0|            0|      0|35.3|                   0.134| 29|      0|\n",
      "|          2|    197|           70|           45|    543|30.5|                   0.158| 53|      1|\n",
      "|          8|    125|           96|            0|      0| 0.0|                   0.232| 54|      1|\n",
      "|          4|    110|           92|            0|      0|37.6|                   0.191| 30|      0|\n",
      "|         10|    168|           74|            0|      0|38.0|                   0.537| 34|      1|\n",
      "|         10|    139|           80|            0|      0|27.1|                   1.441| 57|      0|\n",
      "|          1|    189|           60|           23|    846|30.1|                   0.398| 59|      1|\n",
      "|          5|    166|           72|           19|    175|25.8|                   0.587| 51|      1|\n",
      "|          7|    100|            0|            0|      0|30.0|                   0.484| 32|      1|\n",
      "|          0|    118|           84|           47|    230|45.8|                   0.551| 31|      1|\n",
      "|          7|    107|           74|            0|      0|29.6|                   0.254| 31|      1|\n",
      "|          1|    103|           30|           38|     83|43.3|                   0.183| 33|      0|\n",
      "|          1|    115|           70|           30|     96|34.6|                   0.529| 32|      1|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# şimdi ise bir değişkeni silme işlemi yapacağız\n",
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8639d319-a79a-4602-87a1-6d196f60c9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Pregnancies=6, Glucose=148, BloodPressure=72, SkinThickness=35, Insulin=0, BMI=33.6, DiabetesPedigreeFunction=0.627, Age=50, Outcome=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c29634a4-2de7-4baf-b539-190a6b461c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+-------------+----+------------------------+---+-------+\n",
      "|Pregnancies|Glucose|BloodPressure|SkinThickness| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
      "+-----------+-------+-------------+-------------+----+------------------------+---+-------+\n",
      "|          6|    148|           72|           35|33.6|                   0.627| 50|      1|\n",
      "|          1|     85|           66|           29|26.6|                   0.351| 31|      0|\n",
      "|          8|    183|           64|            0|23.3|                   0.672| 32|      1|\n",
      "|          1|     89|           66|           23|28.1|                   0.167| 21|      0|\n",
      "|          0|    137|           40|           35|43.1|                   2.288| 33|      1|\n",
      "|          5|    116|           74|            0|25.6|                   0.201| 30|      0|\n",
      "|          3|     78|           50|           32|31.0|                   0.248| 26|      1|\n",
      "|         10|    115|            0|            0|35.3|                   0.134| 29|      0|\n",
      "|          2|    197|           70|           45|30.5|                   0.158| 53|      1|\n",
      "|          8|    125|           96|            0| 0.0|                   0.232| 54|      1|\n",
      "|          4|    110|           92|            0|37.6|                   0.191| 30|      0|\n",
      "|         10|    168|           74|            0|38.0|                   0.537| 34|      1|\n",
      "|         10|    139|           80|            0|27.1|                   1.441| 57|      0|\n",
      "|          1|    189|           60|           23|30.1|                   0.398| 59|      1|\n",
      "|          5|    166|           72|           19|25.8|                   0.587| 51|      1|\n",
      "|          7|    100|            0|            0|30.0|                   0.484| 32|      1|\n",
      "|          0|    118|           84|           47|45.8|                   0.551| 31|      1|\n",
      "|          7|    107|           74|            0|29.6|                   0.254| 31|      1|\n",
      "|          1|    103|           30|           38|43.3|                   0.183| 33|      0|\n",
      "|          1|    115|           70|           30|34.6|                   0.529| 32|      1|\n",
      "+-----------+-------+-------------+-------------+----+------------------------+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.drop(\"Insulin\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "adca0f94-d383-49e3-8892-0495372284db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|Outcome|count|\n",
      "+-------+-----+\n",
      "|      1|  268|\n",
      "|      0|  500|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.groupby(\"Outcome\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "935e7abd-fec4-4d85-8c81-b32340d587ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|Outcome|count|\n",
      "+-------+-----+\n",
      "|      1|  268|\n",
      "|      0|  500|\n",
      "+-------+-----+\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [113]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOutcome\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "spark_df.groupby(\"Outcome\").count().show()[0]\n",
    "# bu şekilde yaptığımız da elemana erişim sağlayamıyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "51b929b2-28e0-45f6-b604-495ff44067db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Outcome  count\n",
       "0        1    268\n",
       "1        0    500"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.groupby(\"Outcome\").count().toPandas()\n",
    "# pandas dataframemine dönüştürdük"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1ad5836a-b933-49ec-8982-d04681eeb11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=spark_df.groupby(\"Outcome\").count().toPandas()\n",
    "# verileri çektikten sonra kendi localimize almamız lazım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d123f5ef-6a72-40b0-93c7-13d420303ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Outcome\n",
       "0        1"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.iloc[0:1,0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23116b2b-f1cb-4d29-b24c-5615671c2950",
   "metadata": {},
   "source": [
    "# SQL İşlemleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7fd45ee8-71d8-4611-ae7a-efae41fa0ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://mehmets-air.bbrouter:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark_uygulama</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=pyspark_uygulama>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c5cd65b0-6324-4391-8da2-8e9aae56b7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df.registerTempTable(\"table_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "dd739d82-6f04-46f4-98e1-25ce877b23db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show databases\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "92f18d6e-1647-4e1b-8198-3222f4bb967e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|         | table_df|       true|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a7ca6b92-4784-4b9b-b384-209b05aa38aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|Glucose|\n",
      "+-------+\n",
      "|    148|\n",
      "|     85|\n",
      "|    183|\n",
      "|     89|\n",
      "|    137|\n",
      "+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select Glucose from table_df\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "91b6d1df-b29c-4afc-adc6-ba5e79df2841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|Outcome|     mean(Glucose)|\n",
      "+-------+------------------+\n",
      "|      1|141.25746268656715|\n",
      "|      0|            109.98|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select Outcome, mean(Glucose) from table_df group by Outcome\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf1f52e-73f6-4c63-9afd-9990c7a40408",
   "metadata": {},
   "source": [
    "# Büyük Veri Görselleştirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e384ee13-3473-42fc-9574-91c2cca21a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f19e42f2-75ad-4399-8910-3de97796c27a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [129]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbarplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOutcome\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspark_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspark_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/seaborn/_decorators.py:46\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass the following variable\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m as \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124mkeyword arg\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrom version 0.12, the only valid positional argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     )\n\u001b[1;32m     45\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate({k: arg \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args)})\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/seaborn/categorical.py:3182\u001b[0m, in \u001b[0;36mbarplot\u001b[0;34m(x, y, hue, data, order, hue_order, estimator, ci, n_boot, units, seed, orient, color, palette, saturation, errcolor, errwidth, capsize, dodge, ax, **kwargs)\u001b[0m\n\u001b[1;32m   3169\u001b[0m \u001b[38;5;129m@_deprecate_positional_args\u001b[39m\n\u001b[1;32m   3170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbarplot\u001b[39m(\n\u001b[1;32m   3171\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3179\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3180\u001b[0m ):\n\u001b[0;32m-> 3182\u001b[0m     plotter \u001b[38;5;241m=\u001b[39m \u001b[43m_BarPlotter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3183\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mci\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_boot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3184\u001b[0m \u001b[43m                          \u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpalette\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaturation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3185\u001b[0m \u001b[43m                          \u001b[49m\u001b[43merrcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdodge\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3188\u001b[0m         ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mgca()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/seaborn/categorical.py:1584\u001b[0m, in \u001b[0;36m_BarPlotter.__init__\u001b[0;34m(self, x, y, hue, data, order, hue_order, estimator, ci, n_boot, units, seed, orient, color, palette, saturation, errcolor, errwidth, capsize, dodge)\u001b[0m\n\u001b[1;32m   1579\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y, hue, data, order, hue_order,\n\u001b[1;32m   1580\u001b[0m              estimator, ci, n_boot, units, seed,\n\u001b[1;32m   1581\u001b[0m              orient, color, palette, saturation, errcolor,\n\u001b[1;32m   1582\u001b[0m              errwidth, capsize, dodge):\n\u001b[1;32m   1583\u001b[0m     \u001b[38;5;124;03m\"\"\"Initialize the plotter.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1584\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestablish_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1585\u001b[0m \u001b[43m                             \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1586\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestablish_colors(color, palette, saturation)\n\u001b[1;32m   1587\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimate_statistic(estimator, ci, n_boot, seed)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/seaborn/categorical.py:144\u001b[0m, in \u001b[0;36m_CategoricalPlotter.establish_variables\u001b[0;34m(self, x, y, hue, data, orient, order, hue_order, units)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Option 2:\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# We are plotting a long-form dataset\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# -----------------------------------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m \n\u001b[1;32m    142\u001b[0m     \u001b[38;5;66;03m# See if we need to get variables from `data`\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(x, x)\n\u001b[1;32m    145\u001b[0m         y \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mget(y, y)\n\u001b[1;32m    146\u001b[0m         hue \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mget(hue, hue)\n",
      "File \u001b[0;32m~/spark/spark-3.3.1-bin-hadoop3/python/pyspark/sql/dataframe.py:1988\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1978\u001b[0m \u001b[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[1;32m   1979\u001b[0m \n\u001b[1;32m   1980\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1985\u001b[0m \u001b[38;5;124;03m[Row(age=2), Row(age=5)]\u001b[39;00m\n\u001b[1;32m   1986\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m-> 1988\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1989\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name)\n\u001b[1;32m   1990\u001b[0m     )\n\u001b[1;32m   1991\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mapply(name)\n\u001b[1;32m   1992\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "sns.barplot(x=\"Outcome\",y=spark_df.Outcome.index,data=spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e008a0de-a468-42fb-b618-5fba186ad7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
       "0            6      148             72  ...                     0.627   50        1\n",
       "1            1       85             66  ...                     0.351   31        0\n",
       "2            8      183             64  ...                     0.672   32        1\n",
       "3            1       89             66  ...                     0.167   21        0\n",
       "4            0      137             40  ...                     2.288   33        1\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf=spark_df.toPandas()\n",
    "sdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d8f343bb-92db-4021-9ffd-89d15963310b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Outcome'>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=\"Outcome\",y=sdf.Outcome.index,data=sdf)\n",
    "# amaç ilk başta büyük veriyi spark'ın gücü ile halledip sonra pandas gerekli işlemleri yapmaktır"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3faab21-6245-4bbe-a15c-b8349b287992",
   "metadata": {},
   "source": [
    "# Uçtan uca büyük veride makine öğrenmesi\n",
    "## Spark Session ve Veri Seti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "db8c3298-43f7-46b2-9f25-b90824f37b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0d15cd43-4495-43c1-9619-8d6df730454b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/04 15:52:45 WARN SparkContext: Another SparkContext is being constructed (or threw an exception in its constructor). This may indicate an error, since only one SparkContext should be running in this JVM (see SPARK-2243). The other SparkContext was created at:\n",
      "org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:67)\n",
      "java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)\n",
      "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:484)\n",
      "py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "py4j.Gateway.invoke(Gateway.java:238)\n",
      "py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "22/11/04 15:52:45 ERROR SparkContext: Error initializing SparkContext.\n",
      "java.nio.channels.UnresolvedAddressException\n",
      "\tat java.base/sun.nio.ch.Net.checkAddress(Net.java:149)\n",
      "\tat java.base/sun.nio.ch.Net.checkAddress(Net.java:157)\n",
      "\tat java.base/sun.nio.ch.ServerSocketChannelImpl.netBind(ServerSocketChannelImpl.java:337)\n",
      "\tat java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:301)\n",
      "\tat io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:134)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:562)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1334)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeBind(AbstractChannelHandlerContext.java:506)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:491)\n",
      "\tat io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:973)\n",
      "\tat io.netty.channel.AbstractChannel.bind(AbstractChannel.java:260)\n",
      "\tat io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:356)\n",
      "\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:503)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n"
     ]
    },
    {
     "ename": "IllegalArgumentException",
     "evalue": "None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [150]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkConf\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkContext\n\u001b[0;32m----> 6\u001b[0m spark \u001b[38;5;241m=\u001b[39m \u001b[43mSparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaster\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappName\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchurn_modellemesi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark.executer.memory\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m16gb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m sc \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39msparkContext\n\u001b[1;32m     15\u001b[0m sc\n",
      "File \u001b[0;32m~/spark/spark-3.3.1-bin-hadoop3/python/pyspark/sql/session.py:269\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m     sparkConf\u001b[38;5;241m.\u001b[39mset(key, value)\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m sc \u001b[38;5;241m=\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparkConf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[1;32m    272\u001b[0m session \u001b[38;5;241m=\u001b[39m SparkSession(sc, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n",
      "File \u001b[0;32m~/spark/spark-3.3.1-bin-hadoop3/python/pyspark/context.py:483\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 483\u001b[0m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n",
      "File \u001b[0;32m~/spark/spark-3.3.1-bin-hadoop3/python/pyspark/context.py:197\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls)\u001b[0m\n\u001b[1;32m    195\u001b[0m SparkContext\u001b[38;5;241m.\u001b[39m_ensure_initialized(\u001b[38;5;28mself\u001b[39m, gateway\u001b[38;5;241m=\u001b[39mgateway, conf\u001b[38;5;241m=\u001b[39mconf)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mappName\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43msparkHome\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpyFiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatchSize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjsc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprofiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mudf_profiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;66;03m# If an error occurs, clean up in order to allow future SparkContext creation:\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop()\n",
      "File \u001b[0;32m~/spark/spark-3.3.1-bin-hadoop3/python/pyspark/context.py:282\u001b[0m, in \u001b[0;36mSparkContext._do_init\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, jsc, profiler_cls, udf_profiler_cls)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvironment[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPYTHONHASHSEED\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPYTHONHASHSEED\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    281\u001b[0m \u001b[38;5;66;03m# Create the Java SparkContext through Py4J\u001b[39;00m\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsc \u001b[38;5;241m=\u001b[39m jsc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_context\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# Reset the SparkConf to the one actually used by the SparkContext in JVM.\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conf \u001b[38;5;241m=\u001b[39m SparkConf(_jconf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsc\u001b[38;5;241m.\u001b[39msc()\u001b[38;5;241m.\u001b[39mconf())\n",
      "File \u001b[0;32m~/spark/spark-3.3.1-bin-hadoop3/python/pyspark/context.py:402\u001b[0m, in \u001b[0;36mSparkContext._initialize_context\u001b[0;34m(self, jconf)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;124;03mInitialize SparkContext in function to allow subclass specific initialization\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mJavaSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjconf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/spark/spark-3.3.1-bin-hadoop3/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1585\u001b[0m, in \u001b[0;36mJavaClass.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1579\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCONSTRUCTOR_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1580\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_command_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1581\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1582\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1584\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1585\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1586\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fqn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1588\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1589\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/spark/spark-3.3.1-bin-hadoop3/python/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: None"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark import SparkContext\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"churn_modellemesi\") \\\n",
    "    .config(\"spark.executer.memory\", \"16gb\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59085ecb-cc15-47ca-8ebf-0503ca40f029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1424eda4-ebd5-410d-a22f-38d24db727e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7439649-6b35-4a8a-a1fd-54c05da0f903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afa75bb-f7d5-427f-85f1-f6355fcb3253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbe40dc-ea0c-4292-92cc-985e44e0cbcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f751428-4269-4a69-b82f-5f8e60468dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fc1175-2e9e-438d-8271-e8ecdffb0fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f37ca1-c3ea-48b0-9c6e-b2b93701b79d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658a0c9b-c900-40d0-9d58-f156c5ce91f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17058f8b-5666-4244-8167-4b9392e5c10b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987606a0-ce58-4b0d-8296-0dcb3d626771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e197b67b-0fe2-450d-8875-3215cc2294a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f159596-d1e9-4f23-8d8a-aea01a19e1d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
